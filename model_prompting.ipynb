{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "551433d6-b57d-408f-bdec-4458816c883b",
   "metadata": {},
   "source": [
    "# GPT model prompting through Azure OpenAI\n",
    "\n",
    "Model predictions are saved into a JSONL-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8caf6f-61d0-41ab-8ede-32eefa0d5e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e10aa32-27bb-4f2b-998b-ef760c8e016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatted prompts containig instructions and text (expected answer is removed during prompting)\n",
    "test_file = \"\"\n",
    "\n",
    "# Results folder\n",
    "res_path = \"\"\n",
    "# Results filename\n",
    "resultfilename = \"\"\n",
    "\n",
    "# API key file location\n",
    "api_key_file = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70c015f-513f-4b54-9676-c16cc1d4521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_examples_to_file(filename, examples):\n",
    "    '''\n",
    "    The function writes the model's responses to a JSONL file.\n",
    "\n",
    "    The function takes in formatted model responses (examples) and writes them into the given file (filename).\n",
    "    '''\n",
    "    \n",
    "    with open(filename, \"a\", encoding='utf-8') as file:\n",
    "        for example in examples:\n",
    "            json.dump(example, file, ensure_ascii=False)\n",
    "            file.write('\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0609ca03-d748-4c83-8e45-b773378149be",
   "metadata": {},
   "source": [
    "## API teave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6ab434-7b8b-417c-a05a-a2e4e77b74b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(openai.__version__) # 0.28.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc4f06d-804b-4252-b7cb-3138b8393ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure API information\n",
    "openai.api_type = \"azure\"\n",
    "\n",
    "# API key\n",
    "with open(api_key_file, 'r') as api_file:\n",
    "    openai.api_key=str(api_file.readline()).strip()\n",
    "    \n",
    "openai.api_base = \"\" # API base\n",
    "openai.api_version = \"\" #API version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0690dd8-7ea8-4ce6-8edd-e5f39eb35ca9",
   "metadata": {},
   "source": [
    "## Mudeli viipamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb4a36b-9801-4f12-93db-dad9b5f369cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "responses = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4185c92c-dbb1-4a45-83d4-f24bdf0020bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPT_predict(system, prompt):\n",
    "    \"\"\"\n",
    "    The function prompts models through the Azure API, which returns the model's response. \n",
    "    In case of an error, the model returns None.\n",
    "    \n",
    "    The function parameters are the system prompt (system) and the model prompt (prompt)\n",
    "    \"\"\"\n",
    "\n",
    "    try: \n",
    "        # Viipan mudelit\n",
    "        response = openai.ChatCompletion.create(\n",
    "            deployment_id = \"\",\n",
    "            model = \"gpt-35-turbo\", # Left as an example\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "        responses.append(response['choices'][0]['message']['content'])\n",
    "        prompts.append(prompt)\n",
    "\n",
    "        return response['choices'][0]['message']['content']\n",
    "    \n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c766256f-d76a-49f4-bc70-4e835eb8de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatted prompts\n",
    "with open(test_file, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# A list for storing all incorrectly formatted model responses.\n",
    "predictions = []\n",
    "\n",
    "# A list for storing all correctly formatted model responses.\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aec811-efc3-49b0-b7ff-481e7d9ebbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the tokens-per-minute limit, the examples were divided into groups of 5 \n",
    "# to fit within the 21k token limit (set during deployment).\n",
    "\n",
    "intervals = []\n",
    "\n",
    "for i in range(35, len(dataset), 5):\n",
    "    n = i+5\n",
    "    if n > len(dataset):\n",
    "        n = len(dataset)\n",
    "    intervals.append((i, n))\n",
    "\n",
    "print(intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0991a11c-5e00-48c8-8d6a-e7355ea29cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = 0\n",
    "\n",
    "# The model is prompted with each example\n",
    "for interval in intervals:\n",
    "    print(interval)\n",
    "\n",
    "    examples = []\n",
    "\n",
    "    for i, message in enumerate(dataset[interval[0]:interval[1]]):\n",
    "        \n",
    "        example = {}\n",
    "        \n",
    "        system_t = message[\"messages\"][0][\"content\"]\n",
    "        text = message[\"messages\"][1][\"content\"]\n",
    "        test_labels = message[\"messages\"][2][\"content\"]\n",
    "    \n",
    "        added = False\n",
    "\n",
    "        # Prompting the model with a single prompt a maximum of 2 times\n",
    "        for j in range(2):\n",
    "            # In case of an error, the model is prompted again with the same prompt\n",
    "            if not added:\n",
    "                predicted_labels = GPT_predict(system_t, text)\n",
    "\n",
    "                if predicted_labels:\n",
    "                    # Replace single quotation marks surrounding strings with double quotation marks\n",
    "                    pattern = r\"(?<=\\W)'|'(?=\\W)\"\n",
    "                    predicted_labels = re.sub(pattern, '\"', predicted_labels)\n",
    "\n",
    "                    # Check if the model returned the response in correct JSON format\n",
    "                    try:\n",
    "                        example[\"original\"] = test_labels\n",
    "                        example[\"predicted\"] = json.loads(predicted_labels)\n",
    "                        \n",
    "                        results.append(example)\n",
    "                        examples.append(example)\n",
    "                        \n",
    "                        added = True\n",
    "                        \n",
    "                    except Exception as error:\n",
    "                        failed += 1\n",
    "                        predictions.append(predicted_labels)\n",
    "\n",
    "    # Writing the existing responses into the results file\n",
    "    write_examples_to_file(res_path+resultfilename, examples)\n",
    "    \n",
    "    # 1 minute wait between groups to stay within the limit\n",
    "    time.sleep(60)\n",
    "\n",
    "print(\"Number of results:\", len(results))\n",
    "print(\"Number of failed examples:\", len(dataset) - len(results))\n",
    "print(\"Number of fixed examples:\", failed - 2*(len(dataset) - len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af97ed55-e31b-4890-b06a-c5b549e99e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
